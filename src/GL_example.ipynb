{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeFitting:\n",
    "    def __init__(self, L, A0, N, M1):\n",
    "        self.N = N\n",
    "        self.M1 = M1\n",
    "        self.L = L\n",
    "        self.A0 = A0\n",
    "\n",
    "        self.n = L.shape[0]\n",
    "\n",
    "    def convexProgram(self, constraints=[], N_const=True, M1_const=True):\n",
    "        \"\"\"Solves the convex minimization problem of the paper.\n",
    "        Note that every \"constraints\" argument must have elements defined as lambda functions of the form:\n",
    "            lambda A,N,M1: cp.sum(A) == 115 \n",
    "        as an example. This is because A, N, M1 is not being defined until the function is being called.\n",
    "        \"\"\"\n",
    "        print(len(constraints))\n",
    "        if len(constraints) > 0:\n",
    "            N_const = False\n",
    "            M1_const = False\n",
    "        if N_const:\n",
    "            N = self.N\n",
    "        else:\n",
    "            N = cp.Variable(shape=(self.n + 1))\n",
    "        if M1_const:\n",
    "            M1 = self.M1\n",
    "        else:\n",
    "            M1 = cp.Variable()\n",
    "        L = self.L\n",
    "        A = cp.Variable(shape=self.n)\n",
    "        constraints_eval = [c(A,N,M1) for c in constraints]\n",
    "        obj = cp.Minimize(\n",
    "            cp.scalar_product(-L, A) -\n",
    "            cp.entr(M1 - cp.sum(A)) - (M1 - cp.sum(A)) +\n",
    "            cp.sum(-cp.entr(N[1:] - A) - (N[1:] - A)) +\n",
    "            cp.sum(-cp.entr(A) - A) -\n",
    "            cp.entr(N[0] - M1 + cp.sum(A)) - (N[0] - M1 + cp.sum(A)) \n",
    "        )\n",
    "        if len(constraints) > 0:\n",
    "            problem = cp.Problem(obj, constraints_eval)\n",
    "            problem.solve(solver=cp.ECOS)\n",
    "            return A, N\n",
    "        problem = cp.Problem(obj)\n",
    "        problem.solve(solver=cp.ECOS)\n",
    "        return A\n",
    "\n",
    "    def GL_linesearch(self):\n",
    "        \"\"\"This implements our function with the line search over root-finding Newton's.\n",
    "        Performs a line search.\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        M1 = self.M1\n",
    "        A = self.A0\n",
    "        A1 = A\n",
    "        diff = 1\n",
    "        i = 1\n",
    "        while diff > 1e-4:\n",
    "            A1 = A\n",
    "            Aplus = A.sum()\n",
    "            a0 = self.M1 - Aplus\n",
    "            b0 = self.N[0] - Aplus\n",
    "            B = self.N[1:] - A\n",
    "            c0 = 1/a0 + 1/b0\n",
    "            c = 1/A + 1/B\n",
    "\n",
    "            # Gradient step in Newton's Method and get ∆A\n",
    "            e = self.L + np.log(a0) + np.log(B) - np.log(A) - np.log(b0)\n",
    "            H = np.ones((self.n,self.n))*c0\n",
    "            H += np.diag(c)\n",
    "            dA = scipy.linalg.solve(H,e,assume_a=\"pos\")\n",
    "            dA_pos = np.where(dA > 0, dA, np.nan)\n",
    "            dA_neg = np.where(dA < 0, dA, np.nan)\n",
    "\n",
    "            # Taking minimum over positive change values\n",
    "            A_pos = np.where(dA>0, A, np.nan)\n",
    "            N_pos = np.where(dA>0, (N[1:]), np.nan)\n",
    "            pre_alpha1 = (N_pos - A_pos)/(dA_pos)\n",
    "            pre_alpha1 = np.nan_to_num(pre_alpha1, nan=1e10)\n",
    "            alpha1 = np.min(pre_alpha1) # take smallest element from here\n",
    "\n",
    "            # Taking minimum over negative change values\n",
    "            A_neg = np.where(dA<0, A, np.nan)\n",
    "            pre_alpha2 = -A_neg / dA_neg\n",
    "            pre_alpha2 = np.nan_to_num(pre_alpha2, nan=1e10)\n",
    "            alpha2 = np.min(pre_alpha2)\n",
    "\n",
    "            # Choosing the smallest alpha (step size)\n",
    "            alpha = 0.99*np.min(np.array([alpha1,alpha2,1]))\n",
    "            # alpha = 0.5\n",
    "\n",
    "            # Update A\n",
    "            A += alpha*dA\n",
    "            i += 1\n",
    "            diff = np.linalg.norm(A1 - A)\n",
    "        return A, a0, B, b0, i\n",
    "\n",
    "    def GL(self):\n",
    "        \"\"\"Standard GL method.\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        M1 = self.M1\n",
    "        A = self.A0\n",
    "        A1 = A\n",
    "        diff = 1\n",
    "        i = 1\n",
    "        while diff > 1e-4:\n",
    "            A1 = A\n",
    "            Aplus = A.sum()\n",
    "            a0 = self.M1 - Aplus\n",
    "            b0 = self.N[0] - Aplus\n",
    "            B = self.N[1:] - A\n",
    "            c0 = 1/a0 + 1/b0\n",
    "            c = 1/A + 1/B\n",
    "\n",
    "            # Gradient step in Newton's Method and get ∆A\n",
    "            e = self.L + np.log(a0) + np.log(B) - np.log(A) - np.log(b0)\n",
    "            H = np.ones((self.n,self.n))*c0\n",
    "            H += np.diag(c)\n",
    "            A += scipy.linalg.solve(H,e,assume_a=\"pos\")\n",
    "            i += 1\n",
    "            diff = np.linalg.norm(A1 - A)\n",
    "        return A, a0, B, b0, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2,6,11])\n",
    "Nx = np.array([337,167,186,212])\n",
    "M1x = 451\n",
    "Lx = np.array([np.log(0.80),np.log(1.16),np.log(1.57)])\n",
    "vx = np.array([0.0542,0.0563,0.0563])\n",
    "A0 = M1x*Nx[1:]/(Nx.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_fit_ex = IterativeFitting(Lx,A0,Nx,M1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "A = it_fit_ex.convexProgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable((3,), var1807)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_GLN = it_fit_ex.GL_linesearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 79.93869991, 106.13845038, 136.85534803]),\n",
       " 168.5,\n",
       " array([ 83.5,  93. , 106. ]),\n",
       " 54.5,\n",
       " 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_GLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
